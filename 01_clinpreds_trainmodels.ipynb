{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "#only need to run these if packages haven't been installed yet\n",
    "#!{sys.executable} -m pip install numpy\n",
    "#!{sys.executable} -m pip install pandas\n",
    "#!{sys.executable} -m pip install sklearn\n",
    "#!{sys.executable} -m pip install matplotlib\n",
    "#!{sys.executable} -m pip install datetime\n",
    "#!{sys.executable} -m pip install seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, GroupKFold, GroupShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and clean up ABCD data\n",
    "# set base dirctories\n",
    "ABCD_base_dir   = 'base_directory_path'\n",
    "\n",
    "#load subj fc data\n",
    "ABCD_fc_df = pd.read_csv(os.path.join(ABCD_base_dir, 'fc_data.csv'), header=None)\n",
    "ABCD_fc_subj = pd.read_csv(os.path.join(ABCD_base_dir, 'fc_subj_data.txt'), header=None)\n",
    "ABCD_fc = ABCD_fc_df.T\n",
    "\n",
    "# load subj demo and clinical data\n",
    "ABCD_subj = pd.read_csv(os.path.join(ABCD_base_dir, 'clin_subj_data.csv'))\n",
    "ABCD_clin = pd.read_csv(os.path.join(ABCD_base_dir, 'clin_subj_data.csv'))\n",
    "\n",
    "#drop duplicate header rows\n",
    "header_row = 0\n",
    "ABCD_subj = ABCD_subj.drop(header_row)\n",
    "ABCD_clin = ABCD_clin.drop(header_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add subj key data to fc data and sort\n",
    "ABCD_fc_subj.columns=['subjectkey']\n",
    "ABCD_fc.insert(0, \"subjectkey\", ABCD_fc_subj, True)\n",
    "ABCD_fc_sorted = ABCD_fc.sort_values(by='subjectkey', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean and sort clinical data\n",
    "mask = ABCD_clin.subjectkey.isin(ABCD_fc_sorted['subjectkey'])\n",
    "ABCD_clin_subjs = ABCD_clin[mask]\n",
    "ABCD_clin_baseline = ABCD_clin_subjs[ABCD_clin_subjs.eventname == 'baseline_year_1_arm_1']\n",
    "ABCD_clin_sorted = ABCD_clin_baseline.sort_values(by='subjectkey', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean and sort subject data\n",
    "mask = ABCD_subj.subjectkey.isin(ABCD_fc_sorted['subjectkey'])\n",
    "ABCD_subj_incl = ABCD_subj[mask]\n",
    "ABCD_subj_baseline = ABCD_subj_incl[ABCD_subj_incl.eventname == 'baseline_year_1_arm_1']\n",
    "ABCD_subj_sorted = ABCD_subj_baseline.sort_values(by='subjectkey', ascending=True)\n",
    "ABCD_subj_data = ABCD_subj_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate and clean clinical variables to be predicted\n",
    "ABCD_clin_data = ABCD_clin_sorted[['cbcl_scr_syn_anxdep_r', 'cbcl_scr_syn_withdep_r',\n",
    "                                  'cbcl_scr_syn_somatic_r', 'cbcl_scr_syn_social_r',\n",
    "                                  'cbcl_scr_syn_thought_r', 'cbcl_scr_syn_attention_r',\n",
    "                                  'cbcl_scr_syn_rulebreak_r', 'cbcl_scr_syn_aggressive_r',\n",
    "                                  'cbcl_scr_syn_internal_r',  'cbcl_scr_syn_external_r',\n",
    "                                  'cbcl_scr_syn_totprob_r', 'cbcl_scr_dsm5_depress_r',\n",
    "                                  'cbcl_scr_dsm5_anxdisord_r', 'cbcl_scr_dsm5_somaticpr_r',\n",
    "                                  'cbcl_scr_dsm5_adhd_r', 'cbcl_scr_dsm5_opposit_r',\n",
    "                                  'cbcl_scr_dsm5_conduct_r', 'cbcl_scr_07_sct_r',\n",
    "                                  'cbcl_scr_07_ocd_r', 'cbcl_scr_07_stress_r']]\n",
    "\n",
    "ABCD_clin_labels = ['AnxDep', 'WithDep', 'Somatic', 'Social', 'Thought', 'Attention',\n",
    "                    'RuleBreak', 'Aggresive', 'Internal', 'External', 'TotProb', 'Depress',\n",
    "                    'AnxDiscord', 'SomaticPr', 'ADHD', 'Opposit', 'Conduct', 'Sluggish', \n",
    "                    'OCD', 'Stress']\n",
    "\n",
    "ABCD_clin_data.columns = ABCD_clin_labels\n",
    "ABCD_clin_data.reset_index(inplace=True)\n",
    "ABCD_clin_data = ABCD_clin_data.drop(columns=['index'])\n",
    "\n",
    "#clean fc data \n",
    "ABCD_fc_data = ABCD_fc_sorted.drop(columns=['subjectkey'])\n",
    "ABCD_fc_data.reset_index(inplace=True) \n",
    "ABCD_fc_data = ABCD_fc_data.drop(columns=['index'])\n",
    "\n",
    "#clean subj data\n",
    "ABCD_subj_data.reset_index(inplace=True) \n",
    "ABCD_subj_data = ABCD_subj_data.drop(columns=['index'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sex-specific variables\n",
    "mask_m = ABCD_subj_sorted.sex=='M'\n",
    "ABCD_subj_m = ABCD_subj_sorted[mask_m]\n",
    "ABCD_clin_m = ABCD_clin_data[mask_m]\n",
    "ABCD_fc_m = ABCD_fc_data[mask_m]\n",
    "\n",
    "mask_f = ABCD_subj_sorted.sex=='F'\n",
    "ABCD_subj_f = ABCD_subj_sorted[mask_f]\n",
    "ABCD_clin_f = ABCD_clin_data[mask_f]\n",
    "ABCD_fc_f = ABCD_fc_data[mask_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of repetitions you want to perform\n",
    "rep = 100\n",
    "#number of folds you want in the cross-validation\n",
    "k = 3\n",
    "#proportion of data you want in your training set and test set\n",
    "train_size = .66\n",
    "test_size = 1-train_size\n",
    "\n",
    "#regression model type\n",
    "regr = Ridge(normalize=True, max_iter=1000000, solver='lsqr')\n",
    "\n",
    "#set hyperparameter grid space you want to search through for the model\n",
    "#adapted from the Thomas Yeo Lab Github: \n",
    "#ThomasYeoLab/CBIG/blob/master/stable_projects/predict_phenotypes/He2019_KRDNN/KR_HCP/CBIG_KRDNN_KRR_HCP.m\n",
    "#alphas = [0, 0.00001, 0.0001, 0.001, 0.004, 0.007, 0.01, 0.04, 0.07, 0.1, 0.4, 0.7, 1, 1.5, 2, 2.5, 3,\n",
    "#          3.5, 4, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 100, 150, 200, 300, 500, 700, 1000, 2000, \n",
    "#          3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "alphas = [0.001, 0.01, 0.1, 1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 100, 150, 200, 300, 500, 700, 1000]\n",
    "\n",
    "\n",
    "#param grid set to the hyperparamters you want to search through\n",
    "paramGrid ={'alpha': alphas}\n",
    "\n",
    "\n",
    "\n",
    "#set x data to be the input variable you want to use\n",
    "X_m = ABCD_fc_m\n",
    "X_f = ABCD_fc_f\n",
    "\n",
    "\n",
    "#set y data to be clin var you want to use\n",
    "#do one at a time to prevent crashes\n",
    "clin_var = 'AnxDep'\n",
    "Y_m = ABCD_clin_m[clin_var]\n",
    "Y_f = ABCD_clin_f[clin_var]\n",
    "\n",
    "#ABCD_clin_labels = ['AnxDep', 'WithDep', 'Somatic', 'Social', 'Thought', 'Attention',\n",
    "#                    'RuleBreak', 'Aggresive', 'Internal', 'External', 'TotProb', 'Depress',\n",
    "#                    'AnxDiscord', 'SomaticPr', 'ADHD', 'Opposit', 'Conduct', 'Sluggish', \n",
    "#                    'OCD', 'Stress']\n",
    "\n",
    "\n",
    "\n",
    "#number of variables \n",
    "#is 1 since training models to predict one clin var at a time\n",
    "n_beh = 1\n",
    "\n",
    "#number of features \n",
    "n_feat = X_f.shape[1]\n",
    "\n",
    "#test within sex only here\n",
    "n_test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create arrays to store variables\n",
    "\n",
    "#r^2 - coefficient of determination\n",
    "r2_m = np.zeros([rep])\n",
    "r2_f = np.zeros([rep])\n",
    "#explained variance\n",
    "var_m = np.zeros([rep])\n",
    "var_f = np.zeros([rep])\n",
    "#correlation between true and predicted (aka prediction accuracy)\n",
    "corr_m = np.zeros([rep])\n",
    "corr_f = np.zeros([rep])\n",
    "#optimised alpha (hyperparameter)\n",
    "opt_alpha_m = np.zeros([rep])\n",
    "opt_alpha_f = np.zeros([rep])\n",
    "#feature importance extracted from the model\n",
    "featimp_m = np.zeros([rep,n_feat])\n",
    "featimp_f = np.zeros([rep,n_feat])\n",
    "#for when the feat weights get haufe-inverted\n",
    "#featimp_haufe_m = np.zeros([rep,n_feat])\n",
    "#featimp_haufe_f = np.zeros([rep,n_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterate through number of models\n",
    "for p in range(rep):\n",
    "    \n",
    "    #print model # you're on\n",
    "    print('Model %d' %(p+1))\n",
    "    \n",
    "    #print time\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    \n",
    "    #split into train/test data\n",
    "    train_inds_m, test_inds_m = next(GroupShuffleSplit(test_size=1-train_size, n_splits=1, random_state = p).split(X_m, groups=ABCD_subj_m['site_id_l']))\n",
    "    train_inds_f, test_inds_f = next(GroupShuffleSplit(test_size=1-train_size, n_splits=1, random_state = p).split(X_f, groups=ABCD_subj_f['site_id_l']))\n",
    "    #x_train, x_test, cog_train, cog_test = train_test_split(X, Y, test_size=1-train_size, shuffle=True, random_state=p)\n",
    "    \n",
    "    #set x values based on indices from split\n",
    "    x_train_m = X_m.iloc[train_inds_m].values\n",
    "    x_test_m = X_m.iloc[test_inds_m].values\n",
    "        \n",
    "    #set y values based on indices from split  \n",
    "    beh_train_m = Y_m.iloc[train_inds_m].values\n",
    "    beh_test_m = Y_m.iloc[test_inds_m].values \n",
    "    \n",
    "    #set x values based on indices from split\n",
    "    x_train_f = X_f.iloc[train_inds_f].values\n",
    "    x_test_f = X_f.iloc[test_inds_f].values\n",
    "        \n",
    "    #set y values based on indices from split  \n",
    "    beh_train_f = Y_f.iloc[train_inds_f].values\n",
    "    beh_test_f = Y_f.iloc[test_inds_f].values \n",
    "    \n",
    "    #convert y values to to double\n",
    "    y_train_m = np.double(beh_train_m)\n",
    "    y_test_m = np.double(beh_test_m)\n",
    "        \n",
    "    y_train_f = np.double(beh_train_f)\n",
    "    y_test_f = np.double(beh_test_f)\n",
    "\n",
    "\n",
    "    #create variables to store nested CV scores, and best parameters from hyperparameter optimisation\n",
    "    best_scores_m = []\n",
    "    best_params_m = []\n",
    "    \n",
    "    best_scores_f = []\n",
    "    best_params_f = []\n",
    "        \n",
    "        \n",
    "    #set parameters for inner and outer loops for CV\n",
    "    cv_split = GroupKFold(n_splits=k)\n",
    "        \n",
    "    print (\"Optimising Male-Trained Models\")\n",
    "            \n",
    "    #define regressor with grid-search CV for inner loop\n",
    "    gridSearch_m = GridSearchCV(estimator=regr, param_grid=paramGrid, n_jobs=-1, verbose=0, cv=cv_split, scoring='explained_variance')\n",
    "\n",
    "    #fit regressor to the model, use site ID as group category again\n",
    "    gridSearch_m.fit(x_train_m, y_train_m, groups=ABCD_subj_m.iloc[train_inds_m]['site_id_l'])\n",
    "\n",
    "    #save parameters corresponding to the best score\n",
    "    best_params_m.append(list(gridSearch_m.best_params_.values()))\n",
    "    best_scores_m.append(gridSearch_m.best_score_)\n",
    "        \n",
    "    print (\"Optimising Female-Trained Models\")\n",
    "        \n",
    "    #define regressor with grid-search CV for inner loop\n",
    "    gridSearch_f = GridSearchCV(estimator=regr, param_grid=paramGrid, n_jobs=-1, verbose=0, cv=cv_split, scoring='explained_variance')\n",
    "\n",
    "    #fit regressor to the model, use site ID as group category again\n",
    "    gridSearch_f.fit(x_train_f, y_train_f, groups=ABCD_subj_f.iloc[train_inds_f]['site_id_l'])\n",
    "\n",
    "    #save parameters corresponding to the best score\n",
    "    best_params_f.append(list(gridSearch_f.best_params_.values()))\n",
    "    best_scores_f.append(gridSearch_f.best_score_)\n",
    "        \n",
    "        \n",
    "    print (\"Evaluating Models\")\n",
    "        \n",
    "    #save optimised alpha values\n",
    "    opt_alpha_m[p] = best_params_m[best_scores_m.index(np.max(best_scores_m))][0]\n",
    "    opt_alpha_f[p] = best_params_f[best_scores_f.index(np.max(best_scores_f))][0]\n",
    "\n",
    "    #fit optimized models\n",
    "    model_m = Ridge(alpha = opt_alpha_m[p], normalize=True, max_iter=1000000, solver='lsqr')\n",
    "    model_m.fit(x_train_m, y_train_m);\n",
    "    \n",
    "    model_f = Ridge(alpha = opt_alpha_f[p], normalize=True, max_iter=1000000, solver='lsqr')\n",
    "    model_f.fit(x_train_f, y_train_f);\n",
    "        \n",
    "        \n",
    "    #evaluate model within sex within behavior\n",
    "    r2_m[p]=model_m.score(x_test_m,y_test_m)\n",
    "    r2_f[p]=model_f.score(x_test_f,y_test_f)\n",
    "        \n",
    "\n",
    "    #predict within sex\n",
    "    preds_m = []\n",
    "    preds_f = []\n",
    "        \n",
    "    preds_m = model_m.predict(x_test_m).ravel()\n",
    "    preds_f = model_f.predict(x_test_f).ravel()\n",
    "        \n",
    "        \n",
    "    #compute explained variance \n",
    "    var_m[p] = explained_variance_score(y_test_m, preds_m)\n",
    "    var_f[p] = explained_variance_score(y_test_f, preds_f)\n",
    "\n",
    "\n",
    "    #compute correlation between true and predicted (prediction accuracy)\n",
    "    corr_m[p] = np.corrcoef(y_test_m.ravel(), preds_m)[1,0]\n",
    "    corr_f[p] = np.corrcoef(y_test_f.ravel(), preds_f)[1,0]\n",
    "\n",
    "    \n",
    "    #print (\"Haufe-Transforming Feature Weights\")\n",
    "    #cov_x = []\n",
    "    #cov_y = []\n",
    "    \n",
    "    #extract feature importance\n",
    "    #featimp_m[p,:] = model_m.coef_\n",
    "    #featimp_f[p,:] = model_f.coef_\n",
    "    #compute Haufe-inverted feature weights\n",
    "    #cov_x_m = np.cov(np.transpose(x_train_m))\n",
    "    #cov_y_m = np.cov(y_train_m)\n",
    "    #featimp_haufe_m[p,:] = np.matmul(cov_x_m,featimp_m[p,:])*(1/cov_y_m)\n",
    "        \n",
    "    #cov_x_f = np.cov(np.transpose(x_train_f))\n",
    "    #cov_y_f = np.cov(y_train_f)\n",
    "    #featimp_haufe_f[p,:] = np.matmul(cov_x_f,featimp_f[p,:])*(1/cov_y_f)\n",
    "        \n",
    "        \n",
    "    # save results\n",
    "    results_dir   = 'results_directory_path'\n",
    "\n",
    "    np.save((results_dir + '/fc_r2_m_' + clin_var + '.npy'),r2_m)\n",
    "    np.save((results_dir + '/fc_var_m_' + clin_var + '.npy'),var_m)\n",
    "    np.save((results_dir + '/fc_corr_m_' + clin_var + '.npy'),corr_m)\n",
    "    np.save((results_dir + '/fc_alpha_m_' + clin_var + '.npy'),opt_alpha_m)\n",
    "    np.save((results_dir + '/fc_featimp_m_' + clin_var + '.npy'),featimp_m)\n",
    "    #np.save((results_dir + '/fc_featimp_haufe_m_' + clin_var + '.npy'),featimp_haufe_m)\n",
    "\n",
    "    np.save((results_dir + '/fc_r2_f_' + clin_var + '.npy'),r2_f)\n",
    "    np.save((results_dir + '/fc_var_f_' + clin_var + '.npy'),var_f)\n",
    "    np.save((results_dir + '/fc_corr_f_' + clin_var + '.npy'),corr_f)\n",
    "    np.save((results_dir + '/fc_alpha_f_' + clin_var + '.npy'),opt_alpha_f)\n",
    "    np.save((results_dir + '/fc_featimp_f_' + clin_var + '.npy'),featimp_f)\n",
    "    #np.save((results_dir + '/fc_featimp_haufe_f_' + clin_var + '.npy'),featimp_haufe_f)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
